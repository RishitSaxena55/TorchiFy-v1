# ğŸ”¦ MyTorch: A Minimal PyTorch-like Deep Learning Library

Welcome to **MyTorch**, a minimalist deep learning library implemented from scratch**.

This project is designed to replicate core features of PyTorch's `nn.Module` and autograd systems, providing a hands-on understanding of how deep learning libraries work under the hood.

---

## ğŸ“ Project Structure


- â”œâ”€â”€ hw1p1_autograder.py # Autograder to test the implementation
- â”œâ”€â”€ mytorch/
- â”‚ â”œâ”€â”€ init.py
- â”‚ â”œâ”€â”€ nn/
- â”‚ â”‚ â”œâ”€â”€ init.py
- â”‚ â”‚ â”œâ”€â”€ linear.py # Custom Linear Layer
- â”‚ â”‚ â”œâ”€â”€ activation.py # Custom ReLU, Sigmoid, etc.
- â”‚ â”‚ â”œâ”€â”€ loss.py # Custom CrossEntropyLoss
- â”‚ â””â”€â”€ util.py # Utility functions (e.g., one-hot encoder)
- â””â”€â”€ models/
- â””â”€â”€ mlp0.py # Example MLP model built using MyTorch
- â”œâ”€â”€ requirements.txt

---


---

## ğŸš€ Features Implemented

âœ… Custom implementation of:
- `Linear` layer with forward and backward pass  
- `ReLU` activation function  
- `Sigmoid` activation function  
- `CrossEntropyLoss`  
- Backpropagation using analytical gradients  
- Simple Multi-layer Perceptron (MLP) network (`MLP0`)  
- Unit tests and autograder support  

---

## ğŸ› ï¸ How to Use

1. **Clone the Repository**

```bash
git clone https://github.com/RishitSaxena55/MyTorch-v1.git
cd MyTorch-v1
